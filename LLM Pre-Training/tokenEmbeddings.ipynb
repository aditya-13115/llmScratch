{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c55a486-8c0e-4406-aed2-ca6b80c38400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are going to use pretrained word2vec model by google.. but in real world we first train these embedding along with the LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66af02f5-5e1d-46b3-a074-25344872af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5fec40-c42e-4f91-a6dc-1050dec47f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"word2vec-google-news-300\")  # download the model and return as object ready for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50f45f8-0de9-42e7-8ee2-c9a8f4cef55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.07421875e-01 -2.01171875e-01  1.23046875e-01  2.11914062e-01\n",
      " -9.13085938e-02  2.16796875e-01 -1.31835938e-01  8.30078125e-02\n",
      "  2.02148438e-01  4.78515625e-02  3.66210938e-02 -2.45361328e-02\n",
      "  2.39257812e-02 -1.60156250e-01 -2.61230469e-02  9.71679688e-02\n",
      " -6.34765625e-02  1.84570312e-01  1.70898438e-01 -1.63085938e-01\n",
      " -1.09375000e-01  1.49414062e-01 -4.65393066e-04  9.61914062e-02\n",
      "  1.68945312e-01  2.60925293e-03  8.93554688e-02  6.49414062e-02\n",
      "  3.56445312e-02 -6.93359375e-02 -1.46484375e-01 -1.21093750e-01\n",
      " -2.27539062e-01  2.45361328e-02 -1.24511719e-01 -3.18359375e-01\n",
      " -2.20703125e-01  1.30859375e-01  3.66210938e-02 -3.63769531e-02\n",
      " -1.13281250e-01  1.95312500e-01  9.76562500e-02  1.26953125e-01\n",
      "  6.59179688e-02  6.93359375e-02  1.02539062e-02  1.75781250e-01\n",
      " -1.68945312e-01  1.21307373e-03 -2.98828125e-01 -1.15234375e-01\n",
      "  5.66406250e-02 -1.77734375e-01 -2.08984375e-01  1.76757812e-01\n",
      "  2.38037109e-02 -2.57812500e-01 -4.46777344e-02  1.88476562e-01\n",
      "  5.51757812e-02  5.02929688e-02 -1.06933594e-01  1.89453125e-01\n",
      " -1.16210938e-01  8.49609375e-02 -1.71875000e-01  2.45117188e-01\n",
      " -1.73828125e-01 -8.30078125e-03  4.56542969e-02 -1.61132812e-02\n",
      "  1.86523438e-01 -6.05468750e-02 -4.17480469e-02  1.82617188e-01\n",
      "  2.20703125e-01 -1.22558594e-01 -2.55126953e-02 -3.08593750e-01\n",
      "  9.13085938e-02  1.60156250e-01  1.70898438e-01  1.19628906e-01\n",
      "  7.08007812e-02 -2.64892578e-02 -3.08837891e-02  4.06250000e-01\n",
      " -1.01562500e-01  5.71289062e-02 -7.26318359e-03 -9.17968750e-02\n",
      " -1.50390625e-01 -2.55859375e-01  2.16796875e-01 -3.63769531e-02\n",
      "  2.24609375e-01  8.00781250e-02  1.56250000e-01  5.27343750e-02\n",
      "  1.50390625e-01 -1.14746094e-01 -8.64257812e-02  1.19140625e-01\n",
      " -7.17773438e-02  2.73437500e-01 -1.64062500e-01  7.29370117e-03\n",
      "  4.21875000e-01 -1.12792969e-01 -1.35742188e-01 -1.31835938e-01\n",
      " -1.37695312e-01 -7.66601562e-02  6.25000000e-02  4.98046875e-02\n",
      " -1.91406250e-01 -6.03027344e-02  2.27539062e-01  5.88378906e-02\n",
      " -3.24218750e-01  5.41992188e-02 -1.35742188e-01  8.17871094e-03\n",
      " -5.24902344e-02 -1.74713135e-03 -9.81445312e-02 -2.86865234e-02\n",
      "  3.61328125e-02  2.15820312e-01  5.98144531e-02 -3.08593750e-01\n",
      " -2.27539062e-01  2.61718750e-01  9.86328125e-02 -5.07812500e-02\n",
      "  1.78222656e-02  1.31835938e-01 -5.35156250e-01 -1.81640625e-01\n",
      "  1.38671875e-01 -3.10546875e-01 -9.71679688e-02  1.31835938e-01\n",
      " -1.16210938e-01  7.03125000e-02  2.85156250e-01  3.51562500e-02\n",
      " -1.01562500e-01 -3.75976562e-02  1.41601562e-01  1.42578125e-01\n",
      " -5.68847656e-02  2.65625000e-01 -2.09960938e-01  9.64355469e-03\n",
      " -6.68945312e-02 -4.83398438e-02 -6.10351562e-02  2.45117188e-01\n",
      " -9.66796875e-02  1.78222656e-02 -1.27929688e-01 -4.78515625e-02\n",
      " -7.26318359e-03  1.79687500e-01  2.78320312e-02 -2.10937500e-01\n",
      " -1.43554688e-01 -1.27929688e-01  1.73339844e-02 -3.60107422e-03\n",
      " -2.04101562e-01  3.63159180e-03 -1.19628906e-01 -6.15234375e-02\n",
      "  5.93261719e-02 -3.23486328e-03 -1.70898438e-01 -3.14941406e-02\n",
      " -8.88671875e-02 -2.89062500e-01  3.44238281e-02 -1.87500000e-01\n",
      "  2.94921875e-01  1.58203125e-01 -1.19628906e-01  7.61718750e-02\n",
      "  6.39648438e-02 -4.68750000e-02 -6.83593750e-02  1.21459961e-02\n",
      " -1.44531250e-01  4.54101562e-02  3.68652344e-02  3.88671875e-01\n",
      "  1.45507812e-01 -2.55859375e-01 -4.46777344e-02 -1.33789062e-01\n",
      " -1.38671875e-01  6.59179688e-02  1.37695312e-01  1.14746094e-01\n",
      "  2.03125000e-01 -4.78515625e-02  1.80664062e-02 -8.54492188e-02\n",
      " -2.48046875e-01 -3.39843750e-01 -2.83203125e-02  1.05468750e-01\n",
      " -2.14843750e-01 -8.74023438e-02  7.12890625e-02  1.87500000e-01\n",
      " -1.12304688e-01  2.73437500e-01 -3.26171875e-01 -1.77734375e-01\n",
      " -4.24804688e-02 -2.69531250e-01  6.64062500e-02 -6.88476562e-02\n",
      " -1.99218750e-01 -7.03125000e-02 -2.43164062e-01 -3.66210938e-02\n",
      " -7.37304688e-02 -1.77734375e-01  9.17968750e-02 -1.25000000e-01\n",
      " -1.65039062e-01 -3.57421875e-01 -2.85156250e-01 -1.66992188e-01\n",
      "  1.97265625e-01 -1.53320312e-01  2.31933594e-02  2.06054688e-01\n",
      "  1.80664062e-01 -2.74658203e-02 -1.92382812e-01 -9.61914062e-02\n",
      " -1.06811523e-02 -4.73632812e-02  6.54296875e-02 -1.25732422e-02\n",
      "  1.78222656e-02 -8.00781250e-02 -2.59765625e-01  9.37500000e-02\n",
      " -7.81250000e-02  4.68750000e-02 -2.22167969e-02  1.86767578e-02\n",
      "  3.11279297e-02  1.04980469e-02 -1.69921875e-01  2.58789062e-02\n",
      " -3.41796875e-02 -1.44042969e-02 -5.46875000e-02 -8.78906250e-02\n",
      "  1.96838379e-03  2.23632812e-01 -1.36718750e-01  1.75781250e-01\n",
      " -1.63085938e-01  1.87500000e-01  3.44238281e-02 -5.63964844e-02\n",
      " -2.27689743e-05  4.27246094e-02  5.81054688e-02 -1.07910156e-01\n",
      " -3.88183594e-02 -2.69531250e-01  3.34472656e-02  9.81445312e-02\n",
      "  5.63964844e-02  2.23632812e-01 -5.49316406e-02  1.46484375e-01\n",
      "  5.93261719e-02 -2.19726562e-01  6.39648438e-02  1.66015625e-02\n",
      "  4.56542969e-02  3.26171875e-01 -3.80859375e-01  1.70898438e-01\n",
      "  5.66406250e-02 -1.04492188e-01  1.38671875e-01 -1.57226562e-01\n",
      "  3.23486328e-03 -4.80957031e-02 -2.48046875e-01 -6.20117188e-02]\n"
     ]
    }
   ],
   "source": [
    "word_vectors=model\n",
    "\n",
    "# Let us look how the vector embedding of a word looks like\n",
    "print(word_vectors['computer'])  # Example: Accessing the vector for the word 'computer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c247c9d-93d3-4c4f-bcea-d6fdd1cc35b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors['computer'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752abe1-c2b7-413e-b76a-296a644b566e",
   "metadata": {},
   "source": [
    "# Similar words\n",
    "\n",
    "# King + Woman - Man = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0795e0-d9d9-49f9-aec4-b5e8e79f0909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581), ('kings', 0.5236844420433044), ('Queen_Consort', 0.5235945582389832), ('queens', 0.5181134343147278), ('sultan', 0.5098593831062317), ('monarchy', 0.5087411999702454)]\n"
     ]
    }
   ],
   "source": [
    "# Example of using most_similar\n",
    "print(word_vectors.most_similar(positive=['king', 'woman'], negative=['man'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "381ebb7e-3e91-40a0-a275-51de84a1a391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apples', 0.5484857559204102), ('fruit', 0.547069787979126), ('apple_juice', 0.5237101316452026), ('pears', 0.4946233034133911), ('fruit_juice', 0.4870796799659729), ('orange_juice', 0.4870457053184509), ('pear_juice', 0.4726735055446625), ('mango', 0.4675799310207367), ('grape', 0.46627816557884216), ('grapes', 0.4602501690387726)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['apple', 'juice'], negative=['orange'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a17368d-de78-44cf-add5-81581b07a1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('physician', 0.6463665962219238), ('doctors', 0.5858404040336609), ('surgeon', 0.5723941326141357), ('dentist', 0.552364706993103), ('cardiologist', 0.5413816571235657), ('neurologist', 0.5271127820014954), ('neurosurgeon', 0.5249835848808289), ('urologist', 0.5247740149497986), ('Doctor', 0.5240625143051147), ('internist', 0.5183223485946655)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['doctor', 'man'], negative=['woman'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1abcbc8-a5cf-4cb7-9598-0391dc6ef959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n_*_gga', 0.6681081652641296), ('niggas', 0.660736083984375), ('ni_**', 0.616046667098999), ('n_*_ggas', 0.5938739776611328), ('kanye', 0.5863003730773926), ('homie', 0.5785610675811768), ('brotha', 0.5744467377662659), ('**_ga', 0.5736035108566284), ('Niggas', 0.5687544345855713), ('Jeezy', 0.5598929524421692)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['black', 'nigga'], negative=['white'], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9185c8c9-647e-4c15-b12a-9ab7f6387586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('grandparents', 0.7126420140266418), ('granddaughter', 0.6968098282814026), ('aunt', 0.6922560334205627), ('maternal_grandmother', 0.6772238612174988), ('grandson', 0.6745303273200989), ('grandpa', 0.6392786502838135), ('uncle', 0.6379201412200928), ('father', 0.6310508847236633), ('maternal_grandfather', 0.6285712122917175), ('grandchildren', 0.6267959475517273)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(positive=['grandfather', 'grandmother'], negative=['man'], topn=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd1c68d-3cd5-4545-a4a1-014433daa8d6",
   "metadata": {},
   "source": [
    "# Let us check the similarity b/w a few pair of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62af1fd5-3073-4aa7-b88a-1cc828644f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76640123\n",
      "0.6510957\n",
      "0.7643474\n",
      "0.8543272\n",
      "0.7594367\n",
      "0.11408084\n"
     ]
    }
   ],
   "source": [
    "# Example of calculating similarity\n",
    "print(word_vectors.similarity('woman', 'man')\n",
    "print(word_vectors.similarity('king', 'queen'))\n",
    "print(word_vectors.similarity('uncle', 'aunt'))\n",
    "print(word_vectors.similarity('boy', 'girl'))\n",
    "print(word_vectors.similarity('nephew', 'niece'))\n",
    "print(word_vectors.similarity('paper', 'water'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770b99f1-4b02-4544-97ec-8673fa2705b1",
   "metadata": {},
   "source": [
    "# Most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7af54a4-4a5b-477e-9aef-b15c0a56d2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('towers', 0.8531750440597534), ('skyscraper', 0.6417425870895386), ('Tower', 0.639177143573761), ('spire', 0.594687819480896), ('responded_Understood_Atlasjet', 0.5931612253189087)]\n"
     ]
    }
   ],
   "source": [
    "print(word_vectors.most_similar(\"tower\", topn=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98941e1e-f07f-482b-a81d-15edf1acf3c0",
   "metadata": {},
   "source": [
    "# Now let us see the vector similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89ace18d-4576-41b8-a7f2-72fd12f9a168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The magnitude of the difference between 'man' and 'woman' is 1.73\n",
      "The magnitude of the difference between 'semiconductor' and 'earthworm' is 5.67\n",
      "The magnitude of the difference between 'nephew' and 'niece' is 1.96\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Words to compare\n",
    "word1 = 'man'\n",
    "word2 = 'woman'\n",
    "\n",
    "word3 = 'semiconductor'\n",
    "word4 = 'earthworm'\n",
    "\n",
    "word5 = 'nephew'\n",
    "word6 = 'niece'\n",
    "\n",
    "# Calculate the vector difference\n",
    "vector_difference1 = model[word1] - model[word2]\n",
    "vector_difference2 = model[word3] - model[word4]\n",
    "vector_difference3 = model[word5] - model[word6]\n",
    "\n",
    "# Calculate the magnitude of the vector difference\n",
    "magnitude_of_difference1 = np.linalg.norm(vector_difference1)\n",
    "magnitude_of_difference2 = np.linalg.norm(vector_difference2)\n",
    "magnitude_of_difference3 = np.linalg.norm(vector_difference3)\n",
    "\n",
    "\n",
    "# Print the magnitude of the difference\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word1, word2, magnitude_of_difference1))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word3, word4, magnitude_of_difference2))\n",
    "print(\"The magnitude of the difference between '{}' and '{}' is {:.2f}\".format(word5, word6, magnitude_of_difference3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee9d54-aace-4e92-ab29-61caebc8dd4c",
   "metadata": {},
   "source": [
    "`np.linalg.norm()` is a **NumPy linear algebra function** that computes the *length* (magnitude) of a vector, or more generally, the norm of an array.\n",
    "\n",
    "---\n",
    "\n",
    "### In your case:\n",
    "\n",
    "```python\n",
    "np.linalg.norm(vector_difference3)\n",
    "```\n",
    "\n",
    "* `vector_difference3` is likely a NumPy array (e.g., the difference between two word embeddings).\n",
    "* `np.linalg.norm(...)` gives the **Euclidean distance from the origin** (the size of that vector).\n",
    "\n",
    "---\n",
    "\n",
    "### Example\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "v = np.array([3, 4])\n",
    "print(np.linalg.norm(v))  # 5.0\n",
    "```\n",
    "\n",
    "That’s because √(3² + 4²) = 5.\n",
    "\n",
    "---\n",
    "\n",
    "### Uses in word embeddings (like Word2Vec)\n",
    "\n",
    "If `vector_difference3` = `model[\"king\"] - model[\"man\"]`,\n",
    "then `np.linalg.norm(vector_difference3)` tells you how **large the difference vector** is.\n",
    "It doesn’t tell you *direction*, just *magnitude*.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
